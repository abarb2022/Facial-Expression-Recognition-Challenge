{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tips_tricks_35_loading_kaggle_data_to_colab.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abarb2022/Facial-Expression-Recognition-Challenge/blob/main/loading_kaggle_data_to_colab%20(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/yEXkEUqK52Q"
      ],
      "metadata": {
        "id": "RfYmOIDroDLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading Kaggle data sets directly into Colab**"
      ],
      "metadata": {
        "id": "SyZxTF7lf7jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the kaggle python library"
      ],
      "metadata": {
        "id": "7lvdgeEMgCoy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlwSaX9akGfG",
        "outputId": "203223d6-4b29-4dcb-cca6-a0660fe4f7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the Google drive so you can store your kaggle API credentials for future use"
      ],
      "metadata": {
        "id": "rw0DfSAggHED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGineQt7dErh",
        "outputId": "304d6202-27b9-4761-9132-365351bbd8a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a directory for kaggle at the temporary instance location on Colab drive.\n",
        "\n",
        "Download your kaggle API key (.json file). You can do this by going to your kaggle account page and clicking 'Create new API token' under the API section."
      ],
      "metadata": {
        "id": "Rvmi3WbigOmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vhywUxLXgjBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ZTkKggcylXfa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to copy the kaggle API credentials to the temporary location... (I recommend placing it on your Google Drive)"
      ],
      "metadata": {
        "id": "rKv_7jNggXv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "DD56NrWmlb5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file to Google Drive and then copy to the temporary location."
      ],
      "metadata": {
        "id": "p3N4it0xrFmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IQq6ZMyTrEfO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the file permissions to read/write to the owner only"
      ],
      "metadata": {
        "id": "p3dHJgtLehrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7ncAtrq2lg5F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Competitions and Datasets are the two types of Kaggle data**"
      ],
      "metadata": {
        "id": "Rb3Zm9VMlu3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Download competition data**\n",
        "\n",
        "If you get 403 Forbidden error, you need to click 'Late Submission' on the Kaggle page for that competition."
      ],
      "metadata": {
        "id": "OrdSFfGjl3Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yNdtoRln8A",
        "outputId": "024d8643-86b6-4c5b-de23-8af6b3c7dfd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 90% 256M/285M [00:00<00:00, 812MB/s] \n",
            "100% 285M/285M [00:00<00:00, 842MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip, in case the downloaded file is zipped. Refresh the files on the left hand side to update the view."
      ],
      "metadata": {
        "id": "fRmXZnHghNAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAs9oVnNoziL",
        "outputId": "6f022065-8a1e-4596-e21e-cccafb4ba1d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "YiZHd4NwQ9tE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df = pd.read_csv('train.csv')\n",
        "# test_df = pd.read_csv('test.csv')\n",
        "data_df = pd.read_csv('icml_face_data.csv')\n",
        "\n",
        "# Let's examine the structure\n",
        "print(data_df.head())\n",
        "print(\"\\nUsage distribution:\")\n",
        "print(data_df[' Usage'].value_counts())"
      ],
      "metadata": {
        "id": "WvpAdjP0I3rJ",
        "outputId": "ce0f23ce-0953-49df-9baa-ff068310361b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   emotion     Usage                                             pixels\n",
            "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
            "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
            "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
            "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
            "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
            "\n",
            "Usage distribution:\n",
            " Usage\n",
            "Training       28709\n",
            "PublicTest      3589\n",
            "PrivateTest     3589\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset class with data augmentation\n",
        "class FacialExpressionDataset(Dataset):\n",
        "    def __init__(self, dataframe, usage_type='Training', transform=None):\n",
        "        self.data = dataframe[dataframe[' Usage'] == usage_type]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx][' pixels']\n",
        "        pixels = np.array([int(pixel) for pixel in pixels.split()], dtype=np.uint8)\n",
        "        image = pixels.reshape(48, 48, 1)  # 48x48x1\n",
        "\n",
        "        # Convert to tensor and normalize\n",
        "        image = transforms.ToTensor()(image).float()\n",
        "        image = transforms.Normalize(mean=[0.5], std=[0.5])(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.data.iloc[idx]['emotion']\n",
        "        return image, label\n",
        "\n",
        "# Data augmentation for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "])"
      ],
      "metadata": {
        "id": "KKw9yXH3LOzP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = FacialExpressionDataset(data_df, 'Training', train_transform)\n",
        "val_dataset = FacialExpressionDataset(data_df, 'PublicTest')\n",
        "test_dataset = FacialExpressionDataset(data_df, 'PrivateTest')\n",
        "\n",
        "print(f\"\\nDataset sizes:\")\n",
        "print(f\"Training: {len(train_dataset)} samples\")\n",
        "print(f\"Validation: {len(val_dataset)} samples\")\n",
        "print(f\"Test: {len(test_dataset)} samples\")"
      ],
      "metadata": {
        "id": "gNmj5DOrJWqj",
        "outputId": "a37bbf4f-2093-46b3-854c-6c6999854e90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset sizes:\n",
            "Training: 28709 samples\n",
            "Validation: 3589 samples\n",
            "Test: 3589 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "xZ1kQU0BLfX5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a more sophisticated model\n",
        "class ImprovedEmotionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(ImprovedEmotionCNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7cLPEBziLySI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "model = ImprovedEmotionCNN(num_classes=7).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)"
      ],
      "metadata": {
        "id": "h7GE3810L3Ee",
        "outputId": "1ddf4360-d275-49d0-e41a-bd9930e9d9b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with early stopping\n",
        "num_epochs = 30\n",
        "best_val_accuracy = 0.0\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    train_accuracy = correct / total\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_accuracy = correct / total\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.4f}')\n",
        "    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "    # Early stopping and model checkpointing\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(\"Saved new best model\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping after {patience} epochs without improvement\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Generate classification report\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']))\n",
        "print(f\"Test Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")"
      ],
      "metadata": {
        "id": "jiZyYYs5L9fq",
        "outputId": "d7024a28-9ba5-41c0-ab88-7cde3ae02b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\n",
            "Train Loss: 1.5698 | Train Acc: 0.3944\n",
            "Val Loss: 1.3307 | Val Acc: 0.4840\n",
            "Saved new best model\n",
            "Epoch 2/30:\n",
            "Train Loss: 1.2780 | Train Acc: 0.5140\n",
            "Val Loss: 1.1752 | Val Acc: 0.5528\n",
            "Saved new best model\n",
            "Epoch 3/30:\n",
            "Train Loss: 1.1863 | Train Acc: 0.5479\n",
            "Val Loss: 1.1531 | Val Acc: 0.5653\n",
            "Saved new best model\n",
            "Epoch 4/30:\n",
            "Train Loss: 1.1251 | Train Acc: 0.5718\n",
            "Val Loss: 1.2035 | Val Acc: 0.5634\n",
            "Epoch 5/30:\n",
            "Train Loss: 1.0900 | Train Acc: 0.5882\n",
            "Val Loss: 1.0777 | Val Acc: 0.5968\n",
            "Saved new best model\n",
            "Epoch 6/30:\n",
            "Train Loss: 1.0543 | Train Acc: 0.6031\n",
            "Val Loss: 1.0451 | Val Acc: 0.5996\n",
            "Saved new best model\n",
            "Epoch 7/30:\n",
            "Train Loss: 1.0260 | Train Acc: 0.6099\n",
            "Val Loss: 1.0583 | Val Acc: 0.6069\n",
            "Saved new best model\n",
            "Epoch 8/30:\n",
            "Train Loss: 1.0097 | Train Acc: 0.6174\n",
            "Val Loss: 1.0430 | Val Acc: 0.6141\n",
            "Saved new best model\n",
            "Epoch 9/30:\n",
            "Train Loss: 0.9718 | Train Acc: 0.6327\n",
            "Val Loss: 1.0258 | Val Acc: 0.6180\n",
            "Saved new best model\n",
            "Epoch 10/30:\n",
            "Train Loss: 0.9505 | Train Acc: 0.6409\n",
            "Val Loss: 1.0040 | Val Acc: 0.6367\n",
            "Saved new best model\n",
            "Epoch 11/30:\n",
            "Train Loss: 0.9368 | Train Acc: 0.6490\n",
            "Val Loss: 1.0075 | Val Acc: 0.6280\n",
            "Epoch 12/30:\n",
            "Train Loss: 0.9108 | Train Acc: 0.6578\n",
            "Val Loss: 1.0081 | Val Acc: 0.6322\n",
            "Epoch 13/30:\n",
            "Train Loss: 0.8913 | Train Acc: 0.6666\n",
            "Val Loss: 0.9945 | Val Acc: 0.6322\n",
            "Epoch 14/30:\n",
            "Train Loss: 0.8679 | Train Acc: 0.6735\n",
            "Val Loss: 1.0084 | Val Acc: 0.6436\n",
            "Saved new best model\n",
            "Epoch 15/30:\n",
            "Train Loss: 0.8514 | Train Acc: 0.6809\n",
            "Val Loss: 0.9712 | Val Acc: 0.6439\n",
            "Saved new best model\n",
            "Epoch 16/30:\n",
            "Train Loss: 0.8263 | Train Acc: 0.6899\n",
            "Val Loss: 0.9652 | Val Acc: 0.6528\n",
            "Saved new best model\n",
            "Epoch 17/30:\n",
            "Train Loss: 0.8138 | Train Acc: 0.6962\n",
            "Val Loss: 0.9594 | Val Acc: 0.6592\n",
            "Saved new best model\n",
            "Epoch 18/30:\n",
            "Train Loss: 0.7890 | Train Acc: 0.7032\n",
            "Val Loss: 0.9819 | Val Acc: 0.6587\n",
            "Epoch 19/30:\n",
            "Train Loss: 0.7709 | Train Acc: 0.7113\n",
            "Val Loss: 0.9891 | Val Acc: 0.6492\n",
            "Epoch 20/30:\n",
            "Train Loss: 0.7483 | Train Acc: 0.7209\n",
            "Val Loss: 0.9647 | Val Acc: 0.6514\n",
            "Epoch 21/30:\n",
            "Train Loss: 0.7271 | Train Acc: 0.7286\n",
            "Val Loss: 1.0119 | Val Acc: 0.6478\n",
            "Epoch 22/30:\n",
            "Train Loss: 0.6545 | Train Acc: 0.7607\n",
            "Val Loss: 0.9479 | Val Acc: 0.6693\n",
            "Saved new best model\n",
            "Epoch 23/30:\n",
            "Train Loss: 0.6259 | Train Acc: 0.7699\n",
            "Val Loss: 0.9498 | Val Acc: 0.6695\n",
            "Saved new best model\n",
            "Epoch 24/30:\n",
            "Train Loss: 0.6178 | Train Acc: 0.7735\n",
            "Val Loss: 0.9526 | Val Acc: 0.6718\n",
            "Saved new best model\n",
            "Epoch 25/30:\n",
            "Train Loss: 0.6069 | Train Acc: 0.7779\n",
            "Val Loss: 0.9512 | Val Acc: 0.6704\n",
            "Epoch 26/30:\n",
            "Train Loss: 0.5920 | Train Acc: 0.7854\n",
            "Val Loss: 0.9550 | Val Acc: 0.6773\n",
            "Saved new best model\n",
            "Epoch 27/30:\n",
            "Train Loss: 0.5843 | Train Acc: 0.7883\n",
            "Val Loss: 0.9515 | Val Acc: 0.6765\n",
            "Epoch 28/30:\n",
            "Train Loss: 0.5790 | Train Acc: 0.7878\n",
            "Val Loss: 0.9506 | Val Acc: 0.6779\n",
            "Saved new best model\n",
            "Epoch 29/30:\n",
            "Train Loss: 0.5780 | Train Acc: 0.7901\n",
            "Val Loss: 0.9504 | Val Acc: 0.6765\n",
            "Epoch 30/30:\n",
            "Train Loss: 0.5782 | Train Acc: 0.7882\n",
            "Val Loss: 0.9495 | Val Acc: 0.6748\n",
            "\n",
            "Test Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.63      0.60      0.61       491\n",
            "     Disgust       0.72      0.71      0.72        55\n",
            "        Fear       0.57      0.48      0.52       528\n",
            "       Happy       0.87      0.90      0.88       879\n",
            "         Sad       0.52      0.55      0.54       594\n",
            "    Surprise       0.79      0.82      0.80       416\n",
            "     Neutral       0.65      0.68      0.66       626\n",
            "\n",
            "    accuracy                           0.69      3589\n",
            "   macro avg       0.68      0.68      0.68      3589\n",
            "weighted avg       0.68      0.69      0.69      3589\n",
            "\n",
            "Test Accuracy: 0.6874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5uQIfy1M6PF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}